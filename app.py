import streamlit as st
import os
from groq import Groq

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="Sentinela IA", page_icon="ü§ñ")

st.title("ü§ñ Sentinela (Llama 3.3)")

# Pega a chave da API
api_key = os.environ.get("GROQ_API_KEY")

if not api_key:
    st.error("‚ö†Ô∏è Chave de API n√£o encontrada. Configure no Render.")
    st.stop()

client = Groq(api_key=api_key)

# Inicializa hist√≥rico
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostra hist√≥rico
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- A M√ÅGICA ACONTECE AQUI ---
def gerar_resposta_limpa(chat_completion):
    """Filtra o c√≥digo feio e entrega s√≥ o texto"""
    for chunk in chat_completion:
        if chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content

if prompt := st.chat_input("Digite sua mensagem..."):
    # Mostra mensagem do usu√°rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Chama a IA
    try:
        chat_completion = client.chat.completions.create(
            messages=[
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ],
            model="llama-3.3-70b-versatile", # Modelo Novo
            stream=True,
        )

        # Mostra resposta limpa
        with st.chat_message("assistant"):
            # Aqui usamos a fun√ß√£o de limpeza
            response = st.write_stream(gerar_resposta_limpa(chat_completion))
            
        st.session_state.messages.append({"role": "assistant", "content": response})

    except Exception as e:
        st.error(f"Erro: {e}")
